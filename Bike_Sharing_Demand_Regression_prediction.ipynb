{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "yLjJCtPM0KBk",
        "2DejudWSA-a0",
        "BhH2vgX9EjGr",
        "P1XJ9OREExlT",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "dJ2tPlVmpsJ0",
        "Fze-IPXLpx6K",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushbupatel333/Bike1_Sharing_Prediction/blob/main/Bike_Sharing_Demand_Regression_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    \n",
        "Bike Sharing Demand Prediction"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Khushbupatel333/Bike1_Sharing_Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nowadays Rental bikes are introduced in many urban cities for the improvement of mobile comfort.Itbis important to make rental bikes avaialbel to the public at the right time as it makes watate of time.Eventyally providing a city with supply of rental bikes become a major concern.\n",
        "\n",
        "The main objective is to predict the bike count required at each hour for supply of rental bikes.\n",
        "\n",
        "The dataset contains information (Temperature,Humidity, Windspeed, dewpoint, visibility, solar radiation, snowfall, rainfall) the number of bike rented per hour."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import math"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding='latin1'\n",
        "file_path='/content/drive/My Drive/Colab Notebooks/BikeSharing.csv'\n",
        "\n",
        "dataset=pd.read_csv(file_path,encoding=encoding)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "25gIpSj5IcYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date : Date of the day\n",
        "\n",
        "Rented_bike_count : Number of rented bike per hour\n",
        "\n",
        "Hour : The hour of the day\n",
        "\n",
        "Temperature (°C) : Temperature in celcius\n",
        "\n",
        "Humidity (%) : Humidity in the air\n",
        "\n",
        "Wind_speed(m/s) : speed of the wind m/s\n",
        "\n",
        "Visiblity (10m) : visiblity in m,type\n",
        "\n",
        "Dew_point(°C) : Temprature of beginning of day\n",
        "\n",
        "Solar_radiation(MJ/m2) : sun contribution\n",
        "\n",
        "Rainfall(mm) : Amount of raining  in m\n",
        "\n",
        "Snowfall (cm) : Amount of snowing in cm\n",
        "\n",
        "Season : Season of the year\n",
        "\n",
        "Holiday : If the day is holiday or not\n",
        "\n",
        "Functioning_day : If the day is functioning or not"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in dataset.columns.tolist():\n",
        " print('Number of unique values:',dataset[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create copy of data to new data\n",
        "\n",
        "df=dataset.copy()\n",
        "\n",
        "#Print all the unique values from dataset\n",
        "print(df.nunique())\n",
        "\n",
        "#Removing Duplicate values\n",
        "duplicate=len(df[df.duplicated()])\n",
        "print(\"Number of duplicate values:\",duplicate)\n",
        "\n",
        "\n",
        "#Count missing values in each column\n",
        "print(df.isnull().sum())\n",
        "#print(df)\n",
        "\n",
        "#All columns in the data have names with symbols so we rename the names of columns\n",
        "df=df.rename(columns={'Rented Bike Count':'Rented_bike_count','Temperature(°C)':'Temperature','Humidity(%)':'Humidity','Wind speed (m/s)':'Wind_speed','Visibility (10cm)':'Visiblity','Dew point temperature(°C)':'Dew_point','Solar Radiation (MJ/m2)':'Solar_Radiation','Rainfall(mm)':'Rainfall','Snowfall (cm)':'Snowfall','Functioning Day':'Functioning_Day'})\n",
        "df.head()\n",
        "\n",
        "\n",
        "#Breaking the date column\n",
        "#Splitting date column because this is in string format as year,month ,day.\n",
        "\n",
        "#Changing the date column into categories\n",
        "\n",
        "df['Date']=df['Date'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%Y\"))\n",
        "df['year']=df['Date'].dt.year\n",
        "df['month']=df['Date'].dt.month\n",
        "df['day']=df['Date'].dt.day_name()\n",
        "\n",
        "\n",
        "#Create new column called Weekends\n",
        "\n",
        "df['Weekends']=df['day'].apply(lambda x:1 if x=='Saturday' or x=='Sunday' else 0)\n",
        "df=df.drop(columns=['Date','day','year'],axis=1)\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting the values\n",
        "print(df['Functioning_Day'].value_counts())\n",
        "print(df['Weekends'].value_counts())"
      ],
      "metadata": {
        "id": "5MBQ2bTM9PhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_fea=['Hour','month','Weekends','Seasons','Holiday','Functioning_Day']\n",
        "num_fea=['Temperature','Humidity','Wind_speed','Visibility (10m)','Dew_point','Solar_Radiation','Rainfall','Snowfall']\n",
        "num_fea"
      ],
      "metadata": {
        "id": "dx89MtWTC4H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I have done some updation and changes in my data using some  built in function and methods.\n",
        "\n",
        "- First of all I copied my data in another variable called df.\n",
        "\n",
        "- Then I used unique() method to fetch unique value from data.So I used unique method on seat_number column to get unique country.So I got list of seat number from data.\n",
        "\n",
        "- After this I used nunique() method to get count of unique values.\n",
        "\n",
        "- Then I checked duplicate values using duplicated method on data.So I got data without duplicate values.\n",
        "\n",
        "- Next step was to find null and missing values and handling them.So using isnull() method I checked my data but there is no missing value.\n",
        "\n",
        "- Then I evaluate null value using method isnull().So I got null or missing values in data.\n",
        "\n",
        "- Then I rename all the features name with new names for easy task.\n",
        "\n",
        "- Then next there is one column date which is in date format so I break date column in year,month and day parts .Then for more created another new feature weekends for the column day.\n",
        "\n",
        "- Then after all this I dropped year,date and day columns to clear the data.\n",
        "\n",
        "- Finally I got well sorted and maintain data with proper format."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We are going to analyse the relation of feature with our dependent variable.Our dependent variable is Rented bike count.***\n",
        "\n",
        "***So we analyse this columns by using some visualisation plots***"
      ],
      "metadata": {
        "id": "9_B4G866-VRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Analysis of Categorical data ***\n",
        "\n",
        "1. Month\n",
        "2. Weekends\n",
        "3. Hour\n",
        "4. Functioning_day\n",
        "5. Season\n",
        "6. Holiday"
      ],
      "metadata": {
        "id": "2i6JGTlc837_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 1 Bar plots for Categorical data"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "\n",
        "#Getting Categorical data\n",
        "cat_col=['Hour','month','Seasons','Holiday','Functioning_Day']\n",
        "\n",
        "\n",
        "#Bar plots for Categorical features and Rented bike count\n",
        "plt.figure(figsize=(15,10))\n",
        "for n,col in enumerate(cat_col):\n",
        " plt.subplot(2,3,n+1)\n",
        " plt.title(col)\n",
        " sns.barplot(data=df,x=col,y='Rented_bike_count');\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are a type of data visualization used to represent the dat in the form of rectangular bars.The heights of bars represent the value of data points and the width of each bar represent the category of data.\n",
        "\n",
        " So, I used line charts to represent my Dataset."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above chart we notice the different level of each feature.There are total of holiday,seasons ,month,functioning_day."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Target variable with Functioning day"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Functioning_Day'])\n",
        "plt.title('Is functioning day affect Rented bike count')\n",
        "plt.legend(['high','low'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is used to represent the occurrence of the observation present in the categorical variables.It uses the concept of bar charts for visual depiction.\n",
        "\n",
        "So I used this plot to represent my data"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see I have used two features Target variable and functioning_day.There you will notice that functioning day is not affecting rented bike count more."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Visualising  Hour column"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "#Visualizing count plot for Hour\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "for n,col in enumerate(['Seasons','Holiday','Functioning_Day','month']):\n",
        " plt.subplot(2,2,n+1)\n",
        " plt.title(col)\n",
        " sns.pointplot(data=df,x='Hour',y='Rented_bike_count',hue=col)\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Point plot represent the estimate of central tendency for the numeric variable by the position of dot.\n",
        "\n",
        "It also provides some indication of the uncertainty around that estimate using error.So,For large dataset it is good visual method."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see I have used pointplot for all the categorical columns to represent the distribution of data ."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Point Plot for Month column"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Creating Count plot for month\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "for n,col in enumerate(['Seasons','Holiday','Functioning_Day']):\n",
        " plt.subplot(1,4,n+1)\n",
        " plt.title(col)\n",
        " sns.pointplot(data=df,x='month',y='Rented_bike_count',hue=col)\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Point plot represent the estimate of the central tendency of a numeric variable by position of the dot and provide some indiction of the estimate using error bars.\n",
        "\n",
        "So ,I used this graph to represent month col woith another columns."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph you can see that how the month features is related or distributed in other features."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Visualisation of Numerical data againts Rented_bike_count"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Numerical data and making new column to store\n",
        "\n",
        "Num_col=['Temperature','Humidity','Windspeed','Visibility','Dew_point_temperature','Solar_Radiation','Rainfall','Snowfall']\n",
        "print(Num_col)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DwfT0-FUfYHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Temperature'])\n",
        "plt.title('Is Temperature affect Rented bike count')\n",
        "plt.legend(['No','Yes'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is used to represent the occurrence of the observation present in the categorical variables.It uses the concept of bar charts for visual depiction.\n",
        "\n",
        "So I used this plot to represent my data"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above graph I used bar plot on Temperature and Target variablecolumn.This graph will help us to know the count of features."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Target variable with Holiday variable"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Holiday'])\n",
        "plt.title('Ia Holiday affect the bike cout')\n",
        "plt.legend(['High','low'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "count plots are used to show count of values in Dataset.Using count charts we see which subgroup is hightes or most common and how other groups are compared.\n",
        "\n",
        "   Then ,I used bar plot to represents the target variable and Holiday columns."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above count plot visualisation I notice the affection of Holiday on Rented bike count feature.\n",
        "\n",
        "You you see Holiday affect somewhere to decrease the number of rented bike ."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 histogram for whole dataset"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting histograms for distribution of data\n",
        "\n",
        "fig=plt.figure(figsize=(15,20))\n",
        "ax=fig.gca()\n",
        "df.hist(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are graphs showing frequency distribution.It represent the number distribution within each given intervals.\n",
        "\n",
        "So to show my data I used histogram to whole data."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Histogram you can check the distribution of each feature in the data.\n",
        "\n",
        "As you can see in above graph there are some features which are important like Hour, Temperature and some are not useful like Weekends ."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart-Bar  plot representation of target variable with Snowfall"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.barplot(x=df['Snowfall'],y=df['Rented_bike_count'],data=df)\n",
        "plt.title('Box plot representation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot is method for graphically depicting group of numerical data through their quartiles.The Bar plots uses the bars for Visualising the data.\n",
        "\n",
        "So,I used this chart to show the distribution."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above bar plot graph you can see the distribution of both variable and how the snow fall  affecting the target variable."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Char-9 Target variable with Season"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Seasons'])\n",
        "plt.title('How much seasons affect Rented bike count')\n",
        "plt.legend(['Summer','Winter','Monsoon'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "countplot is used to represent the occurrence(counts) of the observation present in the categories.It uses the concept of a bar chart for the visual depiction."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used season feature with rented bike count to show how seasons affects the target variable.\n",
        "\n",
        "You can see that every season winter,summer and monsoon are affecting the Rented bike count.Summer and winter seasons affected most of the time ."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "sns.heatmap(df.corr(),annot=True,fmt='.2f')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heat maps are table showing correlation coefficient between variables.A correlation matrix is used to summarise data as input into more advance analysis.The range of correlation is [1,-1].\n",
        "\n",
        "  Hence,I used Heatmap to show relation between my Variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know correlation heatmap is used to calculate the correlation between all pairs of columns in th dataset.\n",
        "\n",
        "You can see close realtive pair .This is showing lots of numbers to look at ,it display them using colors like red, Black, Orange etc."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "sns.pairplot(df,hue='Season')"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seaborn pairplot allow us to pairwise relationship between variables within a Dataset.This create a nice visualise and helps us to understand the data by summrizing a large amount of data in a single figure."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###checking skewness and outliers"
      ],
      "metadata": {
        "id": "O-GN9fYNCBPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking distribution and boxplot for contious features\n",
        "for n,col in enumerate(num_fea):\n",
        " plt.subplot(2,4,n+1)\n",
        " plt.xlabel(col)\n",
        " plt.ylabel('Density')\n",
        " ax=sns.distplot(np.sqrt(df[col]),hist=True,color='y')\n",
        " ax.axvline((df[col]).mean(),color='red')\n",
        " ax.axvline((df[col]).median(),color='black')\n",
        " plt.title(col)\n",
        " plt.tight_layout();\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "for n,col in enumerate(num_fea):\n",
        " plt.subplot(2,4,n+1)\n",
        " plt.ylabel(col)\n",
        " sns.boxplot(x=(df[col]))\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "nPKXzXppCVvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From above graph we have detected the outliers in Rented_bike_count,Snowfall,Rainfall,Soalr_Radiation and Wind_speed column**"
      ],
      "metadata": {
        "id": "nTjs8YlJHKNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#handling skewness in the data\n",
        "\n",
        "df['Rented_bike_count']=np.sqrt(df['Rented_bike_count'])\n",
        "df['Snowfall']=np.cbrt(df['Snowfall'])\n",
        "df['Rainfall']=np.cbrt(df['Rainfall'])\n",
        "df['Solar_Radiation']=np.cbrt(df['Solar_Radiation'])\n",
        "df['Humidity']=np.sqrt(df['Humidity'])"
      ],
      "metadata": {
        "id": "dbAdAr-XHtOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the distribution of continous features after some algorithm\n",
        "for n,col in enumerate(num_fea):\n",
        " plt.subplot(2,4,n+1)\n",
        " plt.xlabel(col)\n",
        " plt.ylabel('Density')\n",
        " ax=sns.distplot(np.sqrt(df[col]),hist=True,color='y')\n",
        " ax.axvline((df[col]).mean(),color='red')\n",
        " ax.axvline((df[col]).median(),color='black')\n",
        " plt.title(col)\n",
        " plt.tight_layout();\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "for n,col in enumerate(num_fea):\n",
        " plt.subplot(2,4,n+1)\n",
        " plt.ylabel(col)\n",
        " sns.boxplot(x=(df[col]))\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "F60qAGkVI41B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After applying square root to the Rented_bike_count columns we find that there is no outlier.**"
      ],
      "metadata": {
        "id": "vP4cC7sxJZX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature selection"
      ],
      "metadata": {
        "id": "hHBR24dJJvXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,15))\n",
        "corr=df.corr()\n",
        "sns.heatmap(corr,annot=True,fmt='.2f')\n",
        "plt.title('Correlation heatmap')"
      ],
      "metadata": {
        "id": "e_1R7zW4J4om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Multicollinearity reduction"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "#There are many features but I want only important feature which are required for my model\n",
        "#Checking multicollinearity\n",
        "\n",
        "#defining VIF\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def cal_vif(x):\n",
        " vif=pd.DataFrame()\n",
        " vif['variables']=x.columns\n",
        " vif['VIF']=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
        " return vif\n",
        "\n",
        "#Checking variance inflation factors\n",
        "vif_cal=cal_vif(df[[i for i in df.describe().columns if i not in ['Rented_bike_count']]])\n",
        "vif_cal\n",
        "#df.head()\n",
        "#I want some features so I have deleted all not required features already"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As you can see Temperature,visiblity,Humudity and Dew_point has high VIF**"
      ],
      "metadata": {
        "id": "4If3eWxwLvw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping dew point because it has high VIF\n",
        "df=df.drop(['Dew_point'],axis=1)\n",
        "\n",
        "#checking VIF\n",
        "vif_cal=cal_vif(df[[i for i in df.describe().columns if i not in ['Rented_bike_count']]])\n",
        "vif_cal"
      ],
      "metadata": {
        "id": "pY8W7jB9LS0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping Hunidity because it has high VIF\n",
        "df=df.drop(['Humidity'],axis=1)\n",
        "\n",
        "#removing Humidity and Dew_point from num_fea\n",
        "num_fea.remove('Humidity')\n",
        "num_fea.remove('Dew_point')"
      ],
      "metadata": {
        "id": "8Teaw3yVOhll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ckecking VIF after removing some features\n",
        "vif_cal"
      ],
      "metadata": {
        "id": "5UxrNWASPelQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#description of objective values\n",
        "df.describe(include='O').T"
      ],
      "metadata": {
        "id": "tyFMqYV2QIz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we can see that highest rented bike is during Spring days. The highest rented bikes is when there is no holidays and Functioning day**"
      ],
      "metadata": {
        "id": "a08znSJQQcKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "PfMHePwxSPh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_fea\n",
        "\n",
        "#Using one Hot Encoding\n",
        "df=pd.get_dummies(df,columns=['Hour','Seasons','Holiday','Functioning_Day','month','Weekends'],drop_first=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yK-_EmXrSQNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# split the dataset into 70:30 ratio\n",
        "\n",
        "#We do some experiments to normalised variable\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x=df.drop(['Rented_bike_count'],axis=1)\n",
        "y=df['Rented_bike_count']\n",
        "\n",
        "#Name of features\n",
        "x_columns=x.columns\n",
        "x_columns\n",
        "#x_train.head()\n",
        "#x_test.head()\n",
        "#y_test.head()\n",
        "#x_train.shape\n",
        "#y_test.shape"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()"
      ],
      "metadata": {
        "id": "OTy2WLKaTqql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Standarizing the  features"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create test and train split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "TWrkEJPsUL53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standrizing the features x_train and x_test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Initializing the Min Max Scaler\n",
        "scaler=StandardScaler()\n",
        "x_train= scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "\n",
        "x_train\n",
        "x_test\n",
        "\n",
        "#Transfrom data\n",
        "x_train=pd.DataFrame(x_train, columns=x_columns)\n",
        "x_test=pd.DataFrame(x_test, columns=x_columns)\n",
        "print(x_train.head())"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Function for feature importance"
      ],
      "metadata": {
        "id": "JqdxE2wcuwtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_importance(model):\n",
        " try:\n",
        "   importance=model.feature_importance_\n",
        "   feature=x_columns\n",
        " except:\n",
        "   importance=np.abs(model.coef_)\n",
        "   feature=x_columns\n",
        " indices=np.argsort(importance)\n",
        " indices=indices[20::-1]\n",
        "\n",
        "\n",
        " plt.figure(figsize=(12,4))\n",
        " plt.barh(range(len(indices)),importance[indices])\n",
        " plt.yticks(range(len(indices)),[feature[i] for i in indices])\n",
        " plt.title('Feature Importance')\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "fBj12rg6u4Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for Score Metric"
      ],
      "metadata": {
        "id": "5WhgL96HN50s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_values(model,x_train,y_train,x_test,y_test):\n",
        " y_pred_train=model.predict(x_train)\n",
        " y_pred_test=model.predict(x_test)\n",
        "\n",
        " #Calculating MSE\n",
        " MSE=mean_squared_error(y_train,y_pred_train)\n",
        " #Calculating RMSE\n",
        " RMSE=np.sqrt(MSE)\n",
        " #Calculating MAE\n",
        " MAE=mean_absolute_error(y_train,y_pred_train)\n",
        " #Calculate R2 and adjusted R2\n",
        " r2=r2_score(y_train,y_pred_train)\n",
        " Adjusted_r2=1-(((1-r2)*(x_test.shape[0]-1))/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "#Creating table for values\n",
        " data_set=[['MAE',round((MAE),3)],['MSE',round((MSE),3)],['RMSE',round((RMSE),3)],['R2_score',round((r2),3)],['Adjusted R2',round((Adjusted_r2),3)]]\n",
        " train_df=pd.DataFrame(data_set,columns=['metrics','train_values'])\n",
        "\n",
        " #Calculating the metric values for testing data\n",
        " MSE=mean_squared_error(y_test,y_pred_test)\n",
        "#Calculating RMSE\n",
        " RMSE=np.sqrt(MSE)\n",
        "#Calculating MAE\n",
        " MAE=mean_absolute_error(y_test,y_pred_test)\n",
        "#Calculate R2 and adjusted R2\n",
        " r2=r2_score(y_test,y_pred_test)\n",
        " Adjusted_r2=1-(((1-r2)*(x_test.shape[0]-1))/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "#Creating table for values\n",
        " data_set=[['MAE',round((MAE),3)],['MSE',round((MSE),3)],['RMSE',round((RMSE),3)],['R2_score',round((r2),3)],['Adjusted R2',round((Adjusted_r2),3)]]\n",
        " test_df=pd.DataFrame(data_set,columns=['metrics','test_values'])\n",
        "\n",
        " metric_values=train_df.merge(test_df,how='inner',on='metrics')\n",
        " print(metric_values)\n",
        "\n",
        " plt.figure(figsize=(4,4))\n",
        " ax=metric_values.plot(kind='bar',x='metrics',rot=0)\n",
        " plt.title(model)\n",
        " ax.legend(bbox_to_anchor=(1.05,1),loc='upper left')\n",
        " plt.show();\n",
        "\n",
        " #Hetroscadacity\n",
        " residuals=y_test-y_pred_test\n",
        " plt.figure(figsize=(9,3))\n",
        " plt.subplot(1,2,1)\n",
        " plt.xlabel('residuals')\n",
        " sns.distplot(residuals);\n",
        "\n",
        " #Plotting the scatterplot\n",
        " plt.subplot(1,2,2)\n",
        " plt.xlabel('scatterplot of residuals')\n",
        " plt.scatter(y_pred_test,residuals)\n",
        " plt.tight_layout();\n",
        "\n",
        " plt.figure(figsize=(12,3))\n",
        " plt.plot((y_pred_test)[:100])\n",
        " plt.plot((np.array(y_test)[:100]))\n",
        " plt.legend(['Predited','Actual'])\n",
        " plt.title('Actual and predicted bike count')\n",
        " plt.show();\n",
        "\n",
        " try:\n",
        "  if model== xgb_model:\n",
        "   result=pd.DataFrame()\n",
        "   model=[Linear_Regression,ridge_regression,model,rf_model,gradient_boosting_regressor,xgb_model]\n",
        "   for i in model:\n",
        "    result=redult.append(metric_values[i],ignore_index=True)\n",
        "   print(result)\n",
        " except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "poyfJ_KlPQIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "#fitting model to the training Dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg=LinearRegression()\n",
        "reg.fit(x_train,y_train)\n",
        "\n",
        "reg.score(x_train,y_train)\n",
        "reg.intercept_\n",
        "\n",
        "reg.coef_\n",
        "\n",
        "#Predicting the model\n",
        "metric_values(reg,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature importance\n",
        "feature_importance(reg)"
      ],
      "metadata": {
        "id": "i4tC5JiMheWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ridge Regression"
      ],
      "metadata": {
        "id": "sHyVBqUsjdpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the packege\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge=Ridge(alpha=0.1)\n",
        "ridge.fit(x_train,y_train)\n",
        "\n",
        "#Getting metric score\n",
        "metric_values(ridge,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "MjkpmBnujlCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Feature importance\n",
        "feature_importance(ridge)"
      ],
      "metadata": {
        "id": "ESSq2TPOkKc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Decision Tree with GridSearchCV"
      ],
      "metadata": {
        "id": "OW_h9mJjkYwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt=DecisionTreeRegressor(random_state=0)\n",
        "dt_params={'max_depth':np.arange(1,50,2),'min_samples_leaf':np.arange(2,15)}\n",
        "\n",
        "gs_dt=GridSearchCV(dt,dt_params,cv=3)\n",
        "gs_dt.fit(x_train,y_train)\n",
        "a=gs_dt.best_params_"
      ],
      "metadata": {
        "id": "sKSOMU-skcSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtr=DecisionTreeRegressor(max_depth=a['max_depth'],min_samples_leaf=a['min_samples_leaf'])\n",
        "model=dtr.fit(x_train,y_train)\n",
        "\n",
        "#Getting metric score\n",
        "metric_values(model,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "tx7Zro1MmIMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the Random Forest classifier to the training set\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "clf=RandomForestRegressor()\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "#predicting the test set result\n",
        "metric_values(clf,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "aQDiyDx_Hilm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso Regressor"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting Decision tree classifier to training dataset\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#Fitting the model\n",
        "L1 = Lasso(alpha=0.01,max_iter=1000)\n",
        "L1.fit(x_train,y_train)\n",
        "\n",
        "L1.score(x_train,y_train)\n",
        "\n",
        "#Predicting the score\n",
        "metric_values(L1,x_train,y_train,x_test,y_test)\n",
        "L1.coef_\n",
        "\n",
        "L1.intercept_"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Feature importance\n",
        "feature_importance(L1)"
      ],
      "metadata": {
        "id": "kDRJCXfPikDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradient Boosting"
      ],
      "metadata": {
        "id": "v5BFDwktn-a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gradient=GradientBoostingRegressor()\n",
        "gradient.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "c3MwzKx_n8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting score metric\n",
        "metric_values(gradient,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "YQU7531yoc4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost Regressor with GridSearchCV"
      ],
      "metadata": {
        "id": "qeh5gZtRwP6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Gradient Boosting Regressor from sklearn.ensemble\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#Parameter for gradient boosting Regressor\n",
        "\n",
        "param= {'n_thread':[4],\n",
        "           'n_estimators':[1000],  #600,400],\n",
        "           'learning_rate':[0.01],  #,0.03,0.1],\n",
        "           'min_child_weight':[2],   #4,8],\n",
        "           'max_depth':[4],   #15,20],\n",
        "           'subsample':[0.5],    #0.5,1],\n",
        "           'eval_metric':['rmse'],\n",
        "           'colsample_bytree':[0.7]\n",
        "\n",
        "          }\n",
        "\n",
        "xg=GridSearchCV(XGBRegressor(),param_grid=param,cv=5)\n",
        "\n",
        "#Fitting the model\n",
        "try:\n",
        " xg.fit(x_train,y_train)\n",
        "except Exception as e:\n",
        " print(f\"Error:{e}\")\n",
        "\n",
        "#Exception handling\n",
        "\n",
        "#Printing Best parameter for model\n",
        "print('The best value to be found out:', xg.best_params_)\n",
        "\n",
        "#Predicting the model\n",
        "best_model=xg.best_estimator_\n",
        "\n",
        "#Getting metric score\n",
        "metric_values(best_model,x_train,y_train,x_test,y_test)"
      ],
      "metadata": {
        "id": "kUMbt15txJpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Score**"
      ],
      "metadata": {
        "id": "w-cQMo1g2DbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "#Specify the column name\n",
        "myTable=PrettyTable(['Model_Name','R2 of train dataset','Adjusted R2 of train dataset','R2 of test dataset ','Adjusted R2 of test dataset'])\n",
        "\n",
        "#adding rows\n",
        "myTable.add_row(['Linear Regression','80%','80%','80%','80%'])\n",
        "myTable.add_row(['Ridge Regression','80%','80%','80%','80%'])\n",
        "myTable.add_row(['Decision tree with GridSearchCV','94%','93%','85%','85%'])\n",
        "myTable.add_row(['Random Forest','98%','98%','91%','91%'])\n",
        "myTable.add_row(['Lasso Regressor','80%','80%','80%','80%'])\n",
        "myTable.add_row(['Gradient Boosting','86%','85%','84%','84%'])\n",
        "myTable.add_row(['Gradient Boosting with GridSearchCV','89%','89%','87%','87%'])\n",
        "\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "M8M4Gb0Z2Ofy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The rented bike count is high on Functioning_day.\n",
        "\n",
        "- The rented bike count is low on Holiday compare to working day.\n",
        "\n",
        "- The Rented bike count is high during summer and winter.\n",
        "\n",
        "- Linear Regression ,Random Forest,Lasso, Gradient Boosting with GridSearchCV gives highest R2 score for models.\n",
        "\n",
        "- Important Features which affect the most are winter and summer season,functioning_day,Temprature,Holiday.\n",
        "\n",
        "- Feature Importance value  for all the models are different.\n",
        "\n",
        "- We can deploy Random Forest,Lasso, Linear regression,Ridge with RandomizedSearchCV.\n",
        "\n",
        "- Therefore,Having a quality knowledge and keeping peace with the ever Ml field would surely help one to stay a step ahead in future."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}